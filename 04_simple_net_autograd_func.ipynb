{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dtype=torch.float\n",
    "device=torch.device(\"cpu\")\n",
    "\n",
    "N,in_,h,out_=64,1000,100,10\n",
    "\n",
    "x=torch.randn(N,in_,dtype=dtype,device=device)\n",
    "y=torch.randn(N,out_,dtype=dtype,device=device)\n",
    "\n",
    "w1=torch.randn(in_,h,dtype=dtype,device=device,requires_grad=True)\n",
    "w2=torch.randn(h,out_,dtype=dtype,device=device,requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyReLU(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx,input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_output):\n",
    "        input,=ctx.saved_tensors\n",
    "        grad_input=grad_output.clone()\n",
    "        grad_input[input<0]=0\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss is 27999522.0.\n",
      "Epoch 1, loss is 6706986.5.\n",
      "Epoch 2, loss is 6220621.5.\n",
      "Epoch 3, loss is 6039416.5.\n",
      "Epoch 4, loss is 6020236.0.\n",
      "Epoch 5, loss is 6051363.5.\n",
      "Epoch 6, loss is 6038731.0.\n",
      "Epoch 7, loss is 5915339.0.\n",
      "Epoch 8, loss is 5640049.0.\n",
      "Epoch 9, loss is 5214246.0.\n",
      "Epoch 10, loss is 4662523.0.\n",
      "Epoch 11, loss is 4044926.0.\n",
      "Epoch 12, loss is 3408374.0.\n",
      "Epoch 13, loss is 2808894.75.\n",
      "Epoch 14, loss is 2270973.25.\n",
      "Epoch 15, loss is 1813740.625.\n",
      "Epoch 16, loss is 1435663.875.\n",
      "Epoch 17, loss is 1132542.25.\n",
      "Epoch 18, loss is 892558.75.\n",
      "Epoch 19, loss is 705402.0625.\n",
      "Epoch 20, loss is 559982.0.\n",
      "Epoch 21, loss is 447592.78125.\n",
      "Epoch 22, loss is 360387.25.\n",
      "Epoch 23, loss is 292638.90625.\n",
      "Epoch 24, loss is 239679.34375.\n",
      "Epoch 25, loss is 198166.71875.\n",
      "Epoch 26, loss is 165372.859375.\n",
      "Epoch 27, loss is 139238.96875.\n",
      "Epoch 28, loss is 118242.5625.\n",
      "Epoch 29, loss is 101230.6640625.\n",
      "Epoch 30, loss is 87325.109375.\n",
      "Epoch 31, loss is 75860.296875.\n",
      "Epoch 32, loss is 66336.1953125.\n",
      "Epoch 33, loss is 58350.0546875.\n",
      "Epoch 34, loss is 51605.375.\n",
      "Epoch 35, loss is 45864.3046875.\n",
      "Epoch 36, loss is 40946.734375.\n",
      "Epoch 37, loss is 36705.20703125.\n",
      "Epoch 38, loss is 33025.1953125.\n",
      "Epoch 39, loss is 29811.384765625.\n",
      "Epoch 40, loss is 26992.04296875.\n",
      "Epoch 41, loss is 24508.77734375.\n",
      "Epoch 42, loss is 22310.14453125.\n",
      "Epoch 43, loss is 20354.158203125.\n",
      "Epoch 44, loss is 18608.9453125.\n",
      "Epoch 45, loss is 17045.962890625.\n",
      "Epoch 46, loss is 15642.3251953125.\n",
      "Epoch 47, loss is 14378.22265625.\n",
      "Epoch 48, loss is 13234.7734375.\n",
      "Epoch 49, loss is 12199.134765625.\n",
      "Epoch 50, loss is 11259.5556640625.\n",
      "Epoch 51, loss is 10404.6220703125.\n",
      "Epoch 52, loss is 9625.421875.\n",
      "Epoch 53, loss is 8913.50390625.\n",
      "Epoch 54, loss is 8262.234375.\n",
      "Epoch 55, loss is 7665.365234375.\n",
      "Epoch 56, loss is 7117.88623046875.\n",
      "Epoch 57, loss is 6614.650390625.\n",
      "Epoch 58, loss is 6151.759765625.\n",
      "Epoch 59, loss is 5725.49169921875.\n",
      "Epoch 60, loss is 5332.611328125.\n",
      "Epoch 61, loss is 4969.751953125.\n",
      "Epoch 62, loss is 4634.61328125.\n",
      "Epoch 63, loss is 4324.55517578125.\n",
      "Epoch 64, loss is 4037.6591796875.\n",
      "Epoch 65, loss is 3771.703857421875.\n",
      "Epoch 66, loss is 3525.1630859375.\n",
      "Epoch 67, loss is 3296.31640625.\n",
      "Epoch 68, loss is 3083.798828125.\n",
      "Epoch 69, loss is 2886.19140625.\n",
      "Epoch 70, loss is 2702.459228515625.\n",
      "Epoch 71, loss is 2531.518798828125.\n",
      "Epoch 72, loss is 2372.414794921875.\n",
      "Epoch 73, loss is 2224.12060546875.\n",
      "Epoch 74, loss is 2085.93212890625.\n",
      "Epoch 75, loss is 1957.040771484375.\n",
      "Epoch 76, loss is 1836.828369140625.\n",
      "Epoch 77, loss is 1724.6270751953125.\n",
      "Epoch 78, loss is 1619.7642822265625.\n",
      "Epoch 79, loss is 1521.8216552734375.\n",
      "Epoch 80, loss is 1430.239501953125.\n",
      "Epoch 81, loss is 1344.583251953125.\n",
      "Epoch 82, loss is 1264.46728515625.\n",
      "Epoch 83, loss is 1189.51513671875.\n",
      "Epoch 84, loss is 1119.283935546875.\n",
      "Epoch 85, loss is 1053.5264892578125.\n",
      "Epoch 86, loss is 991.965087890625.\n",
      "Epoch 87, loss is 934.2371826171875.\n",
      "Epoch 88, loss is 880.1021118164062.\n",
      "Epoch 89, loss is 829.3140869140625.\n",
      "Epoch 90, loss is 781.6707153320312.\n",
      "Epoch 91, loss is 736.9300537109375.\n",
      "Epoch 92, loss is 694.9466552734375.\n",
      "Epoch 93, loss is 655.5098266601562.\n",
      "Epoch 94, loss is 618.4476928710938.\n",
      "Epoch 95, loss is 583.61181640625.\n",
      "Epoch 96, loss is 550.889892578125.\n",
      "Epoch 97, loss is 520.1021118164062.\n",
      "Epoch 98, loss is 491.142822265625.\n",
      "Epoch 99, loss is 463.8999938964844.\n",
      "Epoch 100, loss is 438.25616455078125.\n",
      "Epoch 101, loss is 414.110595703125.\n",
      "Epoch 102, loss is 391.3852233886719.\n",
      "Epoch 103, loss is 369.98358154296875.\n",
      "Epoch 104, loss is 349.8197937011719.\n",
      "Epoch 105, loss is 330.817138671875.\n",
      "Epoch 106, loss is 312.9134216308594.\n",
      "Epoch 107, loss is 296.0406799316406.\n",
      "Epoch 108, loss is 280.1372985839844.\n",
      "Epoch 109, loss is 265.1292724609375.\n",
      "Epoch 110, loss is 250.9710235595703.\n",
      "Epoch 111, loss is 237.60984802246094.\n",
      "Epoch 112, loss is 224.9949951171875.\n",
      "Epoch 113, loss is 213.09194946289062.\n",
      "Epoch 114, loss is 201.85104370117188.\n",
      "Epoch 115, loss is 191.2306671142578.\n",
      "Epoch 116, loss is 181.20547485351562.\n",
      "Epoch 117, loss is 171.73037719726562.\n",
      "Epoch 118, loss is 162.7791290283203.\n",
      "Epoch 119, loss is 154.31707763671875.\n",
      "Epoch 120, loss is 146.31748962402344.\n",
      "Epoch 121, loss is 138.75181579589844.\n",
      "Epoch 122, loss is 131.59808349609375.\n",
      "Epoch 123, loss is 124.83328247070312.\n",
      "Epoch 124, loss is 118.43473052978516.\n",
      "Epoch 125, loss is 112.37799072265625.\n",
      "Epoch 126, loss is 106.64666748046875.\n",
      "Epoch 127, loss is 101.22348022460938.\n",
      "Epoch 128, loss is 96.0870361328125.\n",
      "Epoch 129, loss is 91.22607421875.\n",
      "Epoch 130, loss is 86.62435913085938.\n",
      "Epoch 131, loss is 82.26524353027344.\n",
      "Epoch 132, loss is 78.13255310058594.\n",
      "Epoch 133, loss is 74.21917724609375.\n",
      "Epoch 134, loss is 70.51036834716797.\n",
      "Epoch 135, loss is 66.99735260009766.\n",
      "Epoch 136, loss is 63.665771484375.\n",
      "Epoch 137, loss is 60.50811004638672.\n",
      "Epoch 138, loss is 57.515811920166016.\n",
      "Epoch 139, loss is 54.67595291137695.\n",
      "Epoch 140, loss is 51.9837532043457.\n",
      "Epoch 141, loss is 49.43046951293945.\n",
      "Epoch 142, loss is 47.007755279541016.\n",
      "Epoch 143, loss is 44.70866775512695.\n",
      "Epoch 144, loss is 42.52732467651367.\n",
      "Epoch 145, loss is 40.45722961425781.\n",
      "Epoch 146, loss is 38.492679595947266.\n",
      "Epoch 147, loss is 36.626548767089844.\n",
      "Epoch 148, loss is 34.856746673583984.\n",
      "Epoch 149, loss is 33.174346923828125.\n",
      "Epoch 150, loss is 31.57705307006836.\n",
      "Epoch 151, loss is 30.060991287231445.\n",
      "Epoch 152, loss is 28.619491577148438.\n",
      "Epoch 153, loss is 27.25049591064453.\n",
      "Epoch 154, loss is 25.949926376342773.\n",
      "Epoch 155, loss is 24.71426010131836.\n",
      "Epoch 156, loss is 23.53965950012207.\n",
      "Epoch 157, loss is 22.422775268554688.\n",
      "Epoch 158, loss is 21.361663818359375.\n",
      "Epoch 159, loss is 20.351726531982422.\n",
      "Epoch 160, loss is 19.3922176361084.\n",
      "Epoch 161, loss is 18.479944229125977.\n",
      "Epoch 162, loss is 17.611778259277344.\n",
      "Epoch 163, loss is 16.786462783813477.\n",
      "Epoch 164, loss is 16.001079559326172.\n",
      "Epoch 165, loss is 15.253829956054688.\n",
      "Epoch 166, loss is 14.542978286743164.\n",
      "Epoch 167, loss is 13.866765022277832.\n",
      "Epoch 168, loss is 13.22292709350586.\n",
      "Epoch 169, loss is 12.610188484191895.\n",
      "Epoch 170, loss is 12.027143478393555.\n",
      "Epoch 171, loss is 11.472122192382812.\n",
      "Epoch 172, loss is 10.943411827087402.\n",
      "Epoch 173, loss is 10.439807891845703.\n",
      "Epoch 174, loss is 9.960753440856934.\n",
      "Epoch 175, loss is 9.50422191619873.\n",
      "Epoch 176, loss is 9.069544792175293.\n",
      "Epoch 177, loss is 8.65516185760498.\n",
      "Epoch 178, loss is 8.260841369628906.\n",
      "Epoch 179, loss is 7.885082721710205.\n",
      "Epoch 180, loss is 7.526785373687744.\n",
      "Epoch 181, loss is 7.185689449310303.\n",
      "Epoch 182, loss is 6.860468864440918.\n",
      "Epoch 183, loss is 6.5503249168396.\n",
      "Epoch 184, loss is 6.254542350769043.\n",
      "Epoch 185, loss is 5.973135471343994.\n",
      "Epoch 186, loss is 5.704731464385986.\n",
      "Epoch 187, loss is 5.448838233947754.\n",
      "Epoch 188, loss is 5.2046799659729.\n",
      "Epoch 189, loss is 4.971914291381836.\n",
      "Epoch 190, loss is 4.749939918518066.\n",
      "Epoch 191, loss is 4.53801155090332.\n",
      "Epoch 192, loss is 4.336297035217285.\n",
      "Epoch 193, loss is 4.143586158752441.\n",
      "Epoch 194, loss is 3.959894895553589.\n",
      "Epoch 195, loss is 3.7844460010528564.\n",
      "Epoch 196, loss is 3.6168429851531982.\n",
      "Epoch 197, loss is 3.457148313522339.\n",
      "Epoch 198, loss is 3.304487466812134.\n",
      "Epoch 199, loss is 3.1590564250946045.\n",
      "Epoch 200, loss is 3.020334482192993.\n",
      "Epoch 201, loss is 2.8877604007720947.\n",
      "Epoch 202, loss is 2.7610692977905273.\n",
      "Epoch 203, loss is 2.64013671875.\n",
      "Epoch 204, loss is 2.524751663208008.\n",
      "Epoch 205, loss is 2.414677381515503.\n",
      "Epoch 206, loss is 2.3093338012695312.\n",
      "Epoch 207, loss is 2.208841562271118.\n",
      "Epoch 208, loss is 2.1127641201019287.\n",
      "Epoch 209, loss is 2.0210938453674316.\n",
      "Epoch 210, loss is 1.9334074258804321.\n",
      "Epoch 211, loss is 1.8497823476791382.\n",
      "Epoch 212, loss is 1.7698049545288086.\n",
      "Epoch 213, loss is 1.693244218826294.\n",
      "Epoch 214, loss is 1.6202762126922607.\n",
      "Epoch 215, loss is 1.5504812002182007.\n",
      "Epoch 216, loss is 1.4839775562286377.\n",
      "Epoch 217, loss is 1.420060634613037.\n",
      "Epoch 218, loss is 1.3592408895492554.\n",
      "Epoch 219, loss is 1.3009603023529053.\n",
      "Epoch 220, loss is 1.2452694177627563.\n",
      "Epoch 221, loss is 1.192162036895752.\n",
      "Epoch 222, loss is 1.1412893533706665.\n",
      "Epoch 223, loss is 1.0925801992416382.\n",
      "Epoch 224, loss is 1.0460871458053589.\n",
      "Epoch 225, loss is 1.0015333890914917.\n",
      "Epoch 226, loss is 0.9590017795562744.\n",
      "Epoch 227, loss is 0.9183135032653809.\n",
      "Epoch 228, loss is 0.879350483417511.\n",
      "Epoch 229, loss is 0.8421991467475891.\n",
      "Epoch 230, loss is 0.806505560874939.\n",
      "Epoch 231, loss is 0.7723410129547119.\n",
      "Epoch 232, loss is 0.739886999130249.\n",
      "Epoch 233, loss is 0.7086286544799805.\n",
      "Epoch 234, loss is 0.6788403391838074.\n",
      "Epoch 235, loss is 0.6501941680908203.\n",
      "Epoch 236, loss is 0.6229048371315002.\n",
      "Epoch 237, loss is 0.5967590808868408.\n",
      "Epoch 238, loss is 0.5717295408248901.\n",
      "Epoch 239, loss is 0.5478067398071289.\n",
      "Epoch 240, loss is 0.5248425006866455.\n",
      "Epoch 241, loss is 0.5028783679008484.\n",
      "Epoch 242, loss is 0.4818967282772064.\n",
      "Epoch 243, loss is 0.46180155873298645.\n",
      "Epoch 244, loss is 0.44251304864883423.\n",
      "Epoch 245, loss is 0.42408451437950134.\n",
      "Epoch 246, loss is 0.4064226746559143.\n",
      "Epoch 247, loss is 0.3895634412765503.\n",
      "Epoch 248, loss is 0.3733897805213928.\n",
      "Epoch 249, loss is 0.35791146755218506.\n",
      "Epoch 250, loss is 0.34300437569618225.\n",
      "Epoch 251, loss is 0.3288199305534363.\n",
      "Epoch 252, loss is 0.31525570154190063.\n",
      "Epoch 253, loss is 0.3021852970123291.\n",
      "Epoch 254, loss is 0.2897016108036041.\n",
      "Epoch 255, loss is 0.27774158120155334.\n",
      "Epoch 256, loss is 0.2663629353046417.\n",
      "Epoch 257, loss is 0.25540193915367126.\n",
      "Epoch 258, loss is 0.24486872553825378.\n",
      "Epoch 259, loss is 0.23476620018482208.\n",
      "Epoch 260, loss is 0.22507460415363312.\n",
      "Epoch 261, loss is 0.2158636748790741.\n",
      "Epoch 262, loss is 0.20704855024814606.\n",
      "Epoch 263, loss is 0.19852598011493683.\n",
      "Epoch 264, loss is 0.19038589298725128.\n",
      "Epoch 265, loss is 0.18259531259536743.\n",
      "Epoch 266, loss is 0.17514541745185852.\n",
      "Epoch 267, loss is 0.1679939180612564.\n",
      "Epoch 268, loss is 0.1611204445362091.\n",
      "Epoch 269, loss is 0.15452457964420319.\n",
      "Epoch 270, loss is 0.14825737476348877.\n",
      "Epoch 271, loss is 0.1422191709280014.\n",
      "Epoch 272, loss is 0.13640888035297394.\n",
      "Epoch 273, loss is 0.13083496689796448.\n",
      "Epoch 274, loss is 0.12549889087677002.\n",
      "Epoch 275, loss is 0.12043452262878418.\n",
      "Epoch 276, loss is 0.11555010825395584.\n",
      "Epoch 277, loss is 0.110869862139225.\n",
      "Epoch 278, loss is 0.10635869204998016.\n",
      "Epoch 279, loss is 0.10205475240945816.\n",
      "Epoch 280, loss is 0.09793031960725784.\n",
      "Epoch 281, loss is 0.09393896907567978.\n",
      "Epoch 282, loss is 0.0901428610086441.\n",
      "Epoch 283, loss is 0.08649475872516632.\n",
      "Epoch 284, loss is 0.08300144970417023.\n",
      "Epoch 285, loss is 0.07969717681407928.\n",
      "Epoch 286, loss is 0.07644788175821304.\n",
      "Epoch 287, loss is 0.07338866591453552.\n",
      "Epoch 288, loss is 0.07044931501150131.\n",
      "Epoch 289, loss is 0.0676017552614212.\n",
      "Epoch 290, loss is 0.06485218554735184.\n",
      "Epoch 291, loss is 0.06226356700062752.\n",
      "Epoch 292, loss is 0.05976814404129982.\n",
      "Epoch 293, loss is 0.05736615136265755.\n",
      "Epoch 294, loss is 0.05505684018135071.\n",
      "Epoch 295, loss is 0.052858177572488785.\n",
      "Epoch 296, loss is 0.05074358731508255.\n",
      "Epoch 297, loss is 0.04871286824345589.\n",
      "Epoch 298, loss is 0.046763937920331955.\n",
      "Epoch 299, loss is 0.04490189999341965.\n",
      "Epoch 300, loss is 0.04310428723692894.\n",
      "Epoch 301, loss is 0.041385963559150696.\n",
      "Epoch 302, loss is 0.039731528609991074.\n",
      "Epoch 303, loss is 0.038154710084199905.\n",
      "Epoch 304, loss is 0.03663478419184685.\n",
      "Epoch 305, loss is 0.035169512033462524.\n",
      "Epoch 306, loss is 0.033780187368392944.\n",
      "Epoch 307, loss is 0.03243830427527428.\n",
      "Epoch 308, loss is 0.031156951561570168.\n",
      "Epoch 309, loss is 0.029909908771514893.\n",
      "Epoch 310, loss is 0.028727620840072632.\n",
      "Epoch 311, loss is 0.027593577280640602.\n",
      "Epoch 312, loss is 0.026497257873415947.\n",
      "Epoch 313, loss is 0.02545294724404812.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314, loss is 0.024448556825518608.\n",
      "Epoch 315, loss is 0.02349504642188549.\n",
      "Epoch 316, loss is 0.02256658300757408.\n",
      "Epoch 317, loss is 0.021678773686289787.\n",
      "Epoch 318, loss is 0.020828744396567345.\n",
      "Epoch 319, loss is 0.020009104162454605.\n",
      "Epoch 320, loss is 0.019220629706978798.\n",
      "Epoch 321, loss is 0.018469151109457016.\n",
      "Epoch 322, loss is 0.017744604498147964.\n",
      "Epoch 323, loss is 0.017053574323654175.\n",
      "Epoch 324, loss is 0.01638004556298256.\n",
      "Epoch 325, loss is 0.015756716951727867.\n",
      "Epoch 326, loss is 0.015137114562094212.\n",
      "Epoch 327, loss is 0.014553175307810307.\n",
      "Epoch 328, loss is 0.013984296470880508.\n",
      "Epoch 329, loss is 0.013445435091853142.\n",
      "Epoch 330, loss is 0.012925278395414352.\n",
      "Epoch 331, loss is 0.012429690919816494.\n",
      "Epoch 332, loss is 0.011952332220971584.\n",
      "Epoch 333, loss is 0.011492522433400154.\n",
      "Epoch 334, loss is 0.011051403358578682.\n",
      "Epoch 335, loss is 0.010627571493387222.\n",
      "Epoch 336, loss is 0.010221553035080433.\n",
      "Epoch 337, loss is 0.009830515831708908.\n",
      "Epoch 338, loss is 0.00944883655756712.\n",
      "Epoch 339, loss is 0.009094403125345707.\n",
      "Epoch 340, loss is 0.008743242360651493.\n",
      "Epoch 341, loss is 0.008415257558226585.\n",
      "Epoch 342, loss is 0.008100613951683044.\n",
      "Epoch 343, loss is 0.007791659329086542.\n",
      "Epoch 344, loss is 0.007495664991438389.\n",
      "Epoch 345, loss is 0.007208659779280424.\n",
      "Epoch 346, loss is 0.006937927566468716.\n",
      "Epoch 347, loss is 0.00667980732396245.\n",
      "Epoch 348, loss is 0.006433354690670967.\n",
      "Epoch 349, loss is 0.006191897206008434.\n",
      "Epoch 350, loss is 0.005957622081041336.\n",
      "Epoch 351, loss is 0.0057358648627996445.\n",
      "Epoch 352, loss is 0.005522976163774729.\n",
      "Epoch 353, loss is 0.005318774376064539.\n",
      "Epoch 354, loss is 0.005123327020555735.\n",
      "Epoch 355, loss is 0.00493644317612052.\n",
      "Epoch 356, loss is 0.004760098643600941.\n",
      "Epoch 357, loss is 0.004583639092743397.\n",
      "Epoch 358, loss is 0.004415269009768963.\n",
      "Epoch 359, loss is 0.004251628182828426.\n",
      "Epoch 360, loss is 0.004099706653505564.\n",
      "Epoch 361, loss is 0.003950134385377169.\n",
      "Epoch 362, loss is 0.00380539707839489.\n",
      "Epoch 363, loss is 0.003671957878395915.\n",
      "Epoch 364, loss is 0.003536898409947753.\n",
      "Epoch 365, loss is 0.0034116993192583323.\n",
      "Epoch 366, loss is 0.003288318868726492.\n",
      "Epoch 367, loss is 0.0031743349973112345.\n",
      "Epoch 368, loss is 0.003061839612200856.\n",
      "Epoch 369, loss is 0.0029537780210375786.\n",
      "Epoch 370, loss is 0.002848879899829626.\n",
      "Epoch 371, loss is 0.002750727813690901.\n",
      "Epoch 372, loss is 0.0026551915798336267.\n",
      "Epoch 373, loss is 0.0025609268341213465.\n",
      "Epoch 374, loss is 0.0024743664544075727.\n",
      "Epoch 375, loss is 0.002387704560533166.\n",
      "Epoch 376, loss is 0.0023076310753822327.\n",
      "Epoch 377, loss is 0.0022279894910752773.\n",
      "Epoch 378, loss is 0.0021527630742639303.\n",
      "Epoch 379, loss is 0.0020811683498322964.\n",
      "Epoch 380, loss is 0.0020085610449314117.\n",
      "Epoch 381, loss is 0.0019450656836852431.\n",
      "Epoch 382, loss is 0.001881275326013565.\n",
      "Epoch 383, loss is 0.0018170702969655395.\n",
      "Epoch 384, loss is 0.0017593777738511562.\n",
      "Epoch 385, loss is 0.00170278106816113.\n",
      "Epoch 386, loss is 0.0016470046248286963.\n",
      "Epoch 387, loss is 0.0015942160971462727.\n",
      "Epoch 388, loss is 0.0015429829945787787.\n",
      "Epoch 389, loss is 0.001494740485213697.\n",
      "Epoch 390, loss is 0.0014487624866887927.\n",
      "Epoch 391, loss is 0.001400871085934341.\n",
      "Epoch 392, loss is 0.0013589754234999418.\n",
      "Epoch 393, loss is 0.0013157286448404193.\n",
      "Epoch 394, loss is 0.0012745234416797757.\n",
      "Epoch 395, loss is 0.001237023388966918.\n",
      "Epoch 396, loss is 0.0012004758464172482.\n",
      "Epoch 397, loss is 0.001163811539299786.\n",
      "Epoch 398, loss is 0.001128220115788281.\n",
      "Epoch 399, loss is 0.0010925974929705262.\n",
      "Epoch 400, loss is 0.0010608414886519313.\n",
      "Epoch 401, loss is 0.0010309228673577309.\n",
      "Epoch 402, loss is 0.0009999868925660849.\n",
      "Epoch 403, loss is 0.0009705628035590053.\n",
      "Epoch 404, loss is 0.000941975275054574.\n",
      "Epoch 405, loss is 0.00091430579777807.\n",
      "Epoch 406, loss is 0.0008894104976207018.\n",
      "Epoch 407, loss is 0.0008637040737085044.\n",
      "Epoch 408, loss is 0.0008390328148379922.\n",
      "Epoch 409, loss is 0.0008146079489961267.\n",
      "Epoch 410, loss is 0.0007912669098004699.\n",
      "Epoch 411, loss is 0.0007693340303376317.\n",
      "Epoch 412, loss is 0.0007483428344130516.\n",
      "Epoch 413, loss is 0.0007257950492203236.\n",
      "Epoch 414, loss is 0.0007066946127451956.\n",
      "Epoch 415, loss is 0.0006880073342472315.\n",
      "Epoch 416, loss is 0.0006692481110803783.\n",
      "Epoch 417, loss is 0.0006505345809273422.\n",
      "Epoch 418, loss is 0.0006338228122331202.\n",
      "Epoch 419, loss is 0.0006167472456581891.\n",
      "Epoch 420, loss is 0.0006007030024193227.\n",
      "Epoch 421, loss is 0.0005850535235367715.\n",
      "Epoch 422, loss is 0.0005693936836905777.\n",
      "Epoch 423, loss is 0.0005545343738049269.\n",
      "Epoch 424, loss is 0.0005406332784332335.\n",
      "Epoch 425, loss is 0.0005265031359158456.\n",
      "Epoch 426, loss is 0.0005125295137986541.\n",
      "Epoch 427, loss is 0.0005002845427952707.\n",
      "Epoch 428, loss is 0.0004872573190368712.\n",
      "Epoch 429, loss is 0.0004753333341795951.\n",
      "Epoch 430, loss is 0.00046234403271228075.\n",
      "Epoch 431, loss is 0.00045232620323076844.\n",
      "Epoch 432, loss is 0.00044084872934035957.\n",
      "Epoch 433, loss is 0.00043049780651926994.\n",
      "Epoch 434, loss is 0.000419394054915756.\n",
      "Epoch 435, loss is 0.00040916865691542625.\n",
      "Epoch 436, loss is 0.0003998161409981549.\n",
      "Epoch 437, loss is 0.0003908525686711073.\n",
      "Epoch 438, loss is 0.00038144245627336204.\n",
      "Epoch 439, loss is 0.00037340589915402234.\n",
      "Epoch 440, loss is 0.0003642981464508921.\n",
      "Epoch 441, loss is 0.000356159929651767.\n",
      "Epoch 442, loss is 0.00034797616535797715.\n",
      "Epoch 443, loss is 0.0003394187951926142.\n",
      "Epoch 444, loss is 0.00033248160616494715.\n",
      "Epoch 445, loss is 0.0003252536116633564.\n",
      "Epoch 446, loss is 0.00031731289345771074.\n",
      "Epoch 447, loss is 0.0003103135386481881.\n",
      "Epoch 448, loss is 0.00030299436184577644.\n",
      "Epoch 449, loss is 0.0002964493178296834.\n",
      "Epoch 450, loss is 0.00028931369888596237.\n",
      "Epoch 451, loss is 0.00028300494886934757.\n",
      "Epoch 452, loss is 0.00027762335957959294.\n",
      "Epoch 453, loss is 0.000271978962700814.\n",
      "Epoch 454, loss is 0.0002659253659658134.\n",
      "Epoch 455, loss is 0.00026052669272758067.\n",
      "Epoch 456, loss is 0.00025494053261354566.\n",
      "Epoch 457, loss is 0.00024974465486593544.\n",
      "Epoch 458, loss is 0.0002442847762722522.\n",
      "Epoch 459, loss is 0.00023888578289188445.\n",
      "Epoch 460, loss is 0.0002334228192921728.\n",
      "Epoch 461, loss is 0.00022908531536813825.\n",
      "Epoch 462, loss is 0.00022458976309280843.\n",
      "Epoch 463, loss is 0.0002206383942393586.\n",
      "Epoch 464, loss is 0.00021608537645079195.\n",
      "Epoch 465, loss is 0.00021130488312337548.\n",
      "Epoch 466, loss is 0.0002073947252938524.\n",
      "Epoch 467, loss is 0.00020272666006349027.\n",
      "Epoch 468, loss is 0.00019906400120817125.\n",
      "Epoch 469, loss is 0.00019526583491824567.\n",
      "Epoch 470, loss is 0.00019200898532290012.\n",
      "Epoch 471, loss is 0.00018836626259144396.\n",
      "Epoch 472, loss is 0.0001848850370151922.\n",
      "Epoch 473, loss is 0.0001816485746530816.\n",
      "Epoch 474, loss is 0.0001778379373718053.\n",
      "Epoch 475, loss is 0.00017435007612220943.\n",
      "Epoch 476, loss is 0.00017162994481623173.\n",
      "Epoch 477, loss is 0.00016820260498207062.\n",
      "Epoch 478, loss is 0.00016523245722055435.\n",
      "Epoch 479, loss is 0.00016194459749385715.\n",
      "Epoch 480, loss is 0.00015943362086545676.\n",
      "Epoch 481, loss is 0.00015563506167382002.\n",
      "Epoch 482, loss is 0.0001533327013021335.\n",
      "Epoch 483, loss is 0.00015026942128315568.\n",
      "Epoch 484, loss is 0.0001476247125538066.\n",
      "Epoch 485, loss is 0.00014569165068678558.\n",
      "Epoch 486, loss is 0.00014302892668638378.\n",
      "Epoch 487, loss is 0.0001410924451192841.\n",
      "Epoch 488, loss is 0.00013831396063324064.\n",
      "Epoch 489, loss is 0.0001359426387352869.\n",
      "Epoch 490, loss is 0.00013342360034585.\n",
      "Epoch 491, loss is 0.00013082133955322206.\n",
      "Epoch 492, loss is 0.00012903909373562783.\n",
      "Epoch 493, loss is 0.00012694172619376332.\n",
      "Epoch 494, loss is 0.0001246611209353432.\n",
      "Epoch 495, loss is 0.0001225645828526467.\n",
      "Epoch 496, loss is 0.00012095409329049289.\n",
      "Epoch 497, loss is 0.00011856530181830749.\n",
      "Epoch 498, loss is 0.00011687545338645577.\n",
      "Epoch 499, loss is 0.00011474186612758785.\n"
     ]
    }
   ],
   "source": [
    "lr=1e-6\n",
    "for epoch in range(500):\n",
    "    relu=MyReLU.apply\n",
    "    pred=relu(x.mm(w1)).mm(w2)\n",
    "    \n",
    "    loss=(pred-y).pow(2).sum()\n",
    "    print(\"Epoch %s, loss is %s.\"%(epoch,loss.item()))\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w1-=lr*w1.grad\n",
    "        w2-=lr*w2.grad\n",
    "        \n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
